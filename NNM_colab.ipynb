{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TC3XkMetGWtK"
      },
      "source": [
        "# AMPERIUM NNM (Trainer)\n",
        "This notebook allows you to train a neural amp model based on a pair of input/output WAV files that you have of the amp you want to model.\n",
        "\n",
        "Amp + Cab and only Amp supported.\n",
        "\n",
        "Use 44100 mono input signal.\n",
        "\n",
        "As good input signal for training we can recomend https://github.com/GuitarML/Releases/releases/download/v1.0.0/Proteus_Capture_Utility.zip\n",
        "\n",
        "**To use this notebook**:\n",
        "Go to [colab.research.google.com](https://colab.research.google.com/), select the \"GitHub\" tab, and select this notebook.\n",
        "\n",
        "ðŸ”¶**Before you run**ðŸ”¶\n",
        "\n",
        "Make sure to get a GPU! (Runtime->Change runtime type->Select \"GPU\" from the \"Hardware accelerator\" dropdown menu)\n",
        "\n",
        "âš **Warning**âš \n",
        "\n",
        "Google Colab GPU instances only last for 12 hours.\n",
        "Plan your training accordingly!\n",
        "\n",
        "## Steps:\n",
        "1. Install everything\n",
        "2. Upload audio files\n",
        "3. Settings\n",
        "4. Run & Export\n",
        "5. Download your files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Lq3ad6icwrxG"
      },
      "outputs": [],
      "source": [
        "#@title Step 1: Install\n",
        "#@markdown Install AmperiumNNM and the other Python packages it depends on.\n",
        "\n",
        "!git clone https://github.com/KirillDeLutherSergeev/AmperiumNNM.git '/content/AmperiumNNM'\n",
        "\n",
        "%cd 'AmperiumNNM/'\n",
        "\n",
        "from AudioUtils import *\n",
        "from Training import *\n",
        "from ExportNNM import *\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "fnameInput = ''\n",
        "fnameOutput = ''"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2g_4GtFuGlO8"
      },
      "source": [
        "### Step 2A: Upload audio files\n",
        "Upload the input (DI) and output (reamped) files you want to use as input.wav and output.wav.\n",
        "\n",
        "Or copy both files from your google drive to /content folder in Step 2B."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4KSKSDlW67H2"
      },
      "outputs": [],
      "source": [
        "#@title Step 2B: Mount Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vubIFGphy-L5"
      },
      "outputs": [],
      "source": [
        "#@title Step 2B: { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Find your files in /content/drive folder and copy paths to files.\n",
        "\n",
        "#@markdown Input file path\n",
        "fnameInput = \"/content/drive/MyDrive/ML/Proteus_Capture.wav\" #@param {type:\"string\"}\n",
        "#@markdown Output file path\n",
        "fnameOutput = \"/content/drive/MyDrive/ML/Proteus_5153_ReactIR/Proteus_5153B_ReactIR.wav\" #@param {type:\"string\"}\n",
        "\n",
        "!cp $fnameInput '/content/input.wav'\n",
        "!cp $fnameOutput '/content/output.wav'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-of4kmh0clyt"
      },
      "outputs": [],
      "source": [
        "#@title Step 3: Settings { display-mode: \"form\" }\n",
        "\n",
        "#@markdown NNM file name\n",
        "name = \"EVH5153B_V1\" #@param {type:\"string\"}\n",
        "#@markdown Amp description\n",
        "ampName = \"EVH 5150III 50 Blue channel\" #@param {type:\"string\"}\n",
        "#@markdown Cab description\n",
        "cabName = \"None\" #@param {type:\"string\"}\n",
        "#@markdown Model type\n",
        "modelType = \"Amp\" #@param [\"Amp + Cab\", \"Amp\"]\n",
        "\n",
        "#@markdown The input file start offset in seconds, use it to skip first part of both files. For example Proteus_Capture.wav first second contains a signal for alignment and not needed for training.\n",
        "offsetSeconds = 1 #@param {type:\"number\"}\n",
        "#@markdown The output file delay for alignment purposes. It`s better to have the output signal delayed by 1-3 sample in relation to the input file.\n",
        "delaySamples = 2 #@param {type:\"number\"}\n",
        "\n",
        "#Training parameters\n",
        "learningRate = 0.008\n",
        "epsilon = 1e-08\n",
        "#lossType = \"mse\" #@param [\"mae\", \"mse\"]\n",
        "lossType = \"mse\"\n",
        "\n",
        "#Dataset parameters\n",
        "trainSize = 0.8\n",
        "\n",
        "numSteps = 4096\n",
        "overlap = 256\n",
        "batchSize = 64\n",
        "\n",
        "in_file = '/content/input.wav'\n",
        "out_file = '/content/output.wav'\n",
        "\n",
        "x_all, y_all, sampleRate = load_audio_data(in_file, out_file, offsetSeconds, delaySamples)\n",
        "\n",
        "x_train, y_train, x_test, y_test = prepare_dataset(x_all, y_all, numSteps=numSteps, trainSize=trainSize, overlap=overlap, batchSize=batchSize)\n",
        "\n",
        "if modelType != \"Amp\":\n",
        "  model = build_model(True, True, True, loss=lossType, learningRate=learningRate, epsilon=epsilon)\n",
        "  modelTypeID = get_type_id(11, sampleRate)\n",
        "else:\n",
        "  model = build_model(False, True, False, loss=lossType, learningRate=learningRate, epsilon=epsilon)\n",
        "  modelTypeID = get_type_id(10, sampleRate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4Y5VG18O1Ug"
      },
      "outputs": [],
      "source": [
        "#@title Step 4: Run & Export { display-mode: \"form\" }\n",
        "\n",
        "#@markdown The training can be performed in one or more steps.\n",
        "\n",
        "#@markdown You can first train your model for several epochs, than, if it goes well, set more epochs and run this step again. The training will be continued from the previous state.\n",
        "\n",
        "#@markdown ESR better than 0.1 should be usable, better than 0.01 is ideal, but it takes much more time, 0.05 is OK.\n",
        "\n",
        "#@markdown Epochs to train\n",
        "epochs = 8 #@param {type:\"integer\"}\n",
        "\n",
        "train_model(x_train, y_train, x_test, y_test, model, epochs, batchSize)\n",
        "\n",
        "mfname = name+'.nnm'\n",
        "\n",
        "export_model_to_nnm('/content/'+mfname, 1, 0, model, modelTypeID, ampName, cabName)\n",
        "\n",
        "if os.path.exists(fnameOutput):\n",
        "    export_model_to_nnm(os.path.dirname(fnameOutput)+'/'+mfname, 1, 0, model, modelTypeID, ampName, cabName)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
